{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bita6e133adcd1e45d886e3cdf5747d7530",
   "display_name": "Python 3.6.8 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import cv2,os,time,random,zipfile,fitz,re,shutil\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据，筛选出需要预测的数据\n",
    "my_Data1=\"C:/Users/ASUS/Desktop/problem c/mydata.xlsx\"\n",
    "mydata=pd.read_excel(my_Data1,engine='openpyxl')#用openpyxl代替xlrd，不然不支持xlsx文件\n",
    "\n",
    "# 把两个表格中的数据融合在一起\n",
    "da=mydata[['GlobalID','Lab Status','FileName']]#在数据中选取感兴趣的数据\n",
    "DATA=[]\n",
    "\n",
    "length=len(da['GlobalID'])\n",
    "for i in range(length):\n",
    "    temp=da.loc[i,'Lab Status']\n",
    "    if temp=='Positive ID' or temp=='Unprocessed' or temp=='Unverified':#如果是预测\n",
    "        if da.loc[i,'FileName'] :\n",
    "            temp=[]\n",
    "            temp.append(da.loc[i,'GlobalID'])\n",
    "            temp.append(da.loc[i,'Lab Status'])\n",
    "            temp.append(da.loc[i,'FileName'])\n",
    "            DATA.append(temp)\n",
    "# 增加图片文件信息\n",
    "pd_DATA=pd.DataFrame(DATA,columns=['GlobalID','Lab Status','FileName'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行预测\n",
    "model=load_model(\"C:/Users/ASUS/Desktop/problem c/model03_59_0.02.h5\")\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "run:0.29863799999998264s\n",
      "Total take 1 imges\n",
      "run:0.650297900000055s\n",
      "Total take 2 imges\n",
      "run:0.2796614999999747s\n",
      "Total take 1 imges\n"
     ]
    }
   ],
   "source": [
    "path=\"C:/Users/ASUS/Desktop/problem c/2021MCM_ProblemC_Files\"\n",
    "\n",
    "Positive_ID_Probability=[]\n",
    "for FileName in  pd_DATA['FileName'].values.tolist():\n",
    "    this_path=os.path.join(path,FileName)\n",
    "    if ('png' in FileName or 'jpg'in FileName or 'jfif'in FileName):\n",
    "        create_data_from_img(this_path,Positive_ID_Probability)\n",
    "    elif ('pdf'in FileName):\n",
    "        create_data_from_pdf(this_path,Positive_ID_Probability)\n",
    "    elif('docx'in FileName):\n",
    "        create_data_from_docx(this_path,Positive_ID_Probability)\n",
    "        \n",
    "    elif('MOV'in FileName or 'mp4'in FileName):\n",
    "        create_data_from_video(this_path,Positive_ID_Probability)\n",
    "    elif('zip'in FileName):\n",
    "        create_data_from_zip(this_path,Positive_ID_Probability)\n",
    "    else:\n",
    "        Positive_ID_Probability.append(\"Error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_DATA['Positive ID Probability']=Positive_ID_Probability\n",
    "# 把处理好的数据保存下来\n",
    "writer=pd.ExcelWriter('C:/Users/ASUS/Desktop/problem c/mydata4.xlsx')\n",
    "pd_DATA.to_excel(writer,index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_img(this_path,img=[]):\n",
    "    #用图片数据预测Positive_ID_Probability的概率\n",
    "    if img==[]:\n",
    "        img_array= cv2.imread(this_path,1) #读取照片\n",
    "    else:\n",
    "        img_array=img\n",
    "    image = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    prob = model.predict(image)[0]\n",
    "\n",
    "    result=prob[0]*100\n",
    "    return result\n",
    "\n",
    "def create_data_from_img(this_path,Positive_ID_Probability):\n",
    "    #如果数据是图片，png、jpg、jfif\n",
    "    Positive_ID_Probability.append(predict_from_img(this_path))\n",
    "    \n",
    "    \n",
    "def create_data_from_pdf(this_path,Positive_ID_Probability):\n",
    "    # 在PDF中提取照片信息\n",
    "    pic_path = this_path[0:len(this_path)-4] #解压后的路径\n",
    "    # 创建保存图片的文件夹，如果已经存在则不创建\n",
    "    if os.path.exists(pic_path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(pic_path)\n",
    "\n",
    "    t0 = time.clock()                          # 生成图片初始时间\n",
    "    checkXO = r\"/Type(?= */XObject)\"           # 使用正则表达式来查找图片\n",
    "    checkIM = r\"/Subtype(?= */Image)\"\n",
    "    doc = fitz.open(this_path)                      # 打开pdf文件\n",
    "    imgcount = 0                               # 图片计数\n",
    "    lenXREF = doc._getXrefLength()             # 获取对象数量长度\n",
    "     \n",
    "    result=0\n",
    "\n",
    "    # 遍历每一个对象\n",
    "    for i in range(1, lenXREF):\n",
    "        text = doc._getXrefString(i)            # 定义对象字符串\n",
    "        isXObject = re.search(checkXO, text)    # 使用正则表达式查看是否是对象\n",
    "        isImage = re.search(checkIM, text)      # 使用正则表达式查看是否是图片\n",
    "        if not isXObject or not isImage:        # 如果不是对象也不是图片，则continue\n",
    "            continue\n",
    "        imgcount += 1\n",
    "\n",
    "        pix = fitz.Pixmap(doc, i)               # 生成图像对象\n",
    "        new_name = \"Img{}.png\".format(imgcount) # 生成图片的名称\n",
    "        if pix.n < 5:                           # 如果pix.n<5,可以直接存为PNG\n",
    "            pix.writePNG(os.path.join(pic_path, new_name))\n",
    "        else:                                   # 否则先转换CMYK\n",
    "            pix0 = fitz.Pixmap(fitz.csRGB, pix)\n",
    "            pix0.writePNG(os.path.join(pic_path, new_name))\n",
    "            pix0 = None\n",
    "        pix = None                              # 释放资源\n",
    "        t1 = time.clock()                       # 图片完成时间\n",
    "        print(\"run:{}s\".format(t1 - t0))\n",
    "        print(\"Total take {} imges\".format(imgcount))\n",
    "\n",
    "        # 进到文件夹里边读取图像数据\n",
    "        result=(result+predict_from_img(os.path.join(pic_path, new_name)))/2#取平均值\n",
    "    #记录预测的结果\n",
    "    Positive_ID_Probability.append(result)\n",
    "\n",
    "def create_data_from_docx(this_path,Positive_ID_Probability):\n",
    "    \n",
    "    path=this_path\n",
    "    zip_path=this_path[0:len(this_path)-4]+'zip'\n",
    "    tmp_path=this_path[0:len(this_path)-5]+'temp'\n",
    "    store_path=this_path[0:len(this_path)-5]\n",
    "\n",
    "    # 创建保存图片的文件夹，如果已经存在则不创建\n",
    "    if os.path.exists(tmp_path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(tmp_path)\n",
    "    if os.path.exists(store_path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(store_path)\n",
    "    \n",
    "    # 将docx文件重命名为zip文件\n",
    "    os.rename(path, zip_path)\n",
    "    f = zipfile.ZipFile(zip_path, 'r')# 进行解压\n",
    "    for file in f.namelist():# 将图片提取并保存\n",
    "        f.extract(file, tmp_path)\n",
    "    f.close()# 释放该zip文件\n",
    "\n",
    "    # 将docx文件从zip还原为docx\n",
    "    os.rename(zip_path, path)\n",
    "    # 得到缓存文件夹中图片列表\n",
    "    pic = os.listdir(os.path.join(tmp_path, 'word/media'))\n",
    "\n",
    "    result=0\n",
    "\n",
    "    # 将图片复制到最终的文件夹中\n",
    "    for i in pic:\n",
    "        # 根据word的路径生成图片的名称\n",
    "        new_name = path.replace('\\\\', '_')\n",
    "        new_name = new_name.replace(':', '') + '_' + i\n",
    "        shutil.copy(os.path.join(tmp_path + '/word/media', i), os.path.join(store_path, new_name))\n",
    "\n",
    "        result=(result+predict_from_img(os.path.join(store_path, new_name)))/2#取平均值\n",
    "    #记录预测的结果\n",
    "    Positive_ID_Probability.append(result)\n",
    "\n",
    "    # 删除缓冲文件夹中的文件，用以存储下一次的文件\n",
    "    for i in os.listdir(tmp_path):\n",
    "        # 如果是文件夹则删除\n",
    "        if os.path.isdir(os.path.join(tmp_path, i)):\n",
    "            shutil.rmtree(os.path.join(tmp_path, i))\n",
    "\n",
    "\n",
    "def create_data_from_video(this_path,Positive_ID_Probability):\n",
    "    # 从视频中读取数据，一帧一帧读取\n",
    "    cap = cv2.VideoCapture(this_path)#打开视频\n",
    "   \n",
    "    result=0\n",
    "    \n",
    "    while cap.isOpened():#如果成功打开\n",
    "        rval, image = cap.read()\n",
    "        if rval==True:\n",
    "            result =(result+predict_from_img(this_path,image))/2\n",
    "        else:\n",
    "            break\n",
    "    Positive_ID_Probability.append(result)\n",
    "    \n",
    "def create_data_from_zip(this_path,Positive_ID_Probability):\n",
    "    #从压缩包中得到数据\n",
    "    result=0\n",
    "    with zipfile.ZipFile(this_path, mode='r') as zfile: # 只读方式打开压缩包\n",
    " \n",
    "        for name in zfile.namelist():  # 获取zip文档内所有文件的名称列表\n",
    "            if ('.jpg' not in name) or ('.JPG'not in name):# 仅读取.jpg图片，过滤掉文件夹，及其他非.jpg后缀文件\n",
    "                continue\n",
    "            #print(name)\n",
    "            with zfile.open(name,mode='r') as image_file:\n",
    "                content = image_file.read() # 一次性读入整张图片信息\n",
    "                image = np.asarray(bytearray(content), dtype='uint8')\n",
    "                result=(result+predict_from_img(this_path,image))/2\n",
    "    zfile.close()\n",
    "    Positive_ID_Probability.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}